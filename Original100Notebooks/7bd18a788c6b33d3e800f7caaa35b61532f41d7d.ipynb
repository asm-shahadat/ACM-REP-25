{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd9b9c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\bloodyprof\\anaconda3\\envs\\dl\\lib\\site-packages (from transformers) (2022.4.24)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\bloodyprof\\anaconda3\\envs\\dl\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: requests in c:\\users\\bloodyprof\\anaconda3\\envs\\dl\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp39-cp39-win_amd64.whl (3.3 MB)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0-cp39-cp39-win_amd64.whl (151 kB)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.7.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bloodyprof\\anaconda3\\envs\\dl\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\bloodyprof\\anaconda3\\envs\\dl\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\bloodyprof\\anaconda3\\envs\\dl\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\bloodyprof\\anaconda3\\envs\\dl\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\bloodyprof\\anaconda3\\envs\\dl\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\bloodyprof\\anaconda3\\envs\\dl\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\bloodyprof\\anaconda3\\envs\\dl\\lib\\site-packages (from requests->transformers) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bloodyprof\\anaconda3\\envs\\dl\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\bloodyprof\\anaconda3\\envs\\dl\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Installing collected packages: pyyaml, filelock, tokenizers, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.7.1 huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\bloodyprof\\anaconda3\\envs\\dl\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\bloodyprof\\anaconda3\\envs\\dl\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\bloodyprof\\anaconda3\\envs\\dl\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\bloodyprof\\anaconda3\\envs\\dl\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\bloodyprof\\anaconda3\\envs\\dl\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\bloodyprof\\anaconda3\\envs\\dl\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\bloodyprof\\anaconda3\\envs\\dl\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\bloodyprof\\anaconda3\\envs\\dl\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\bloodyprof\\anaconda3\\envs\\dl\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\bloodyprof\\anaconda3\\envs\\dl\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\bloodyprof\\anaconda3\\envs\\dl\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c19d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e388214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 (https://huggingface.co/sshleifer/distilbart-cnn-12-6)\n"
     ]
    }
   ],
   "source": [
    "summarizer=pipeline('summarization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a58f120",
   "metadata": {},
   "outputs": [],
   "source": [
    "article=\"\"\"\n",
    "Need for tools and techniques to organize, search and understand vast quantities of information is increasing with increasing amounts of data\n",
    "Working on topic modeling technique to extract hidden topical patterns that are present across research papers related to occupant behaviour \n",
    "Using BERTopic for topic modeling which leverages transformers and c-TF-IDF to create dense clusters allowing for easily interpretable topics whilst keeping important words in the topic descriptions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bddc5d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' Using BERTopic for topic modeling which leverages transformers and c-TF-IDF to create dense clusters allowing for easily interpretable topics whilst keeping important words in topic descriptions .'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(article, max_length=50, min_length=10, do_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d71626",
   "metadata": {},
   "source": [
    "According to DeepMind, it can, “play Atari, caption images, chat, stack blocks with a real robot arm and much more, deciding based on its context whether to output text, joint torques, button presses, or other tokens.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55c6ef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "article2=\"\"\"\n",
    "We introduce the Pathways Autoregressive Text-to-Image model (Parti), an autoregressive text-to-image generation model that achieves high-fidelity photorealistic image generation and supports content-rich synthesis involving complex compositions and world knowledge. Recent advances with diffusion models for text-to-image generation, such as Google’s Imagen, have also shown impressive capabilities and state-of-the-art performance on research benchmarks. Parti and Imagen are complementary in exploring two different families of generative models – autoregressive and diffusion, respectively – opening exciting opportunities for combinations of these two powerful models.\n",
    "\n",
    "Parti treats text-to-image generation as a sequence-to-sequence modeling problem, analogous to machine translation – this allows it to benefit from advances in large language models, especially capabilities that are unlocked by scaling data and model sizes. In this case, the target outputs are sequences of image tokens instead of text tokens in another language. Parti uses the powerful image tokenizer, ViT-VQGAN, to encode images as sequences of discrete tokens, and takes advantage of its ability to reconstruct such image token sequences as high quality, visually diverse images.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cbf6e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' Pathways Autoregressive Text-to-Image model (Parti) achieves high-fidelity photorealistic image generation and supports content-rich synthesis involving complex compositions and world knowledge . Parti uses the powerful image tokenizer to encode images as sequences of discrete tokens, and takes advantage of its ability to reconstruct such image token sequences as high quality, visually diverse images .'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(article2, max_length=100, min_length=50, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eed46b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic3=\"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dc55040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' Text-to-image models introduce many opportunities and risks, with potential impact on bias and safety, visual communication, disinformation, and creativity and art . Current models like Parti are trained on large, often noisy, image-text datasets'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(topic3, max_length=50, min_length=25, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bc55cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic4=\"\"\"\n",
    "Text-to-image generation models are all the rage these days, but even this announcement is sudden and a little unexpected. Following so closely the announcement of Imagen, Google research's previous image-to-text generation model, they're deciding to show off another model build to do the same thing.\n",
    "This newest model in the spotlight today is named Parti (Pathways Autoregressive Text-to-Image). While Imagen and DALL·E 2 are diffusion models, Parti follows in DALL·E's footsteps as an autoregressive model. Regardless of architecture and training method, the end use is the same: These models, including Parti, will generate detailed images based on the user's text input.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e664a600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \" Google announces new image-to-image generation model Parti . Parti follows in DALL·E's footsteps as an autoregressive model . The new model will generate detailed images based on text input .\"}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(topic4, max_length=50, min_length=25, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcc2c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic5=\"\"\"\n",
    " Dall-E Mini is an open-source text-to-image AI that's available to the public but is trained on smaller datasets. DALL-E Mini was inspired by a more powerful AI image-making tool called DALL-E (a portmanteau of Salvador Dali and WALL-E), revealed by AI research company OpenAI in January 2021. DALL-E is more powerful but is not openly available, due to concerns that it will be misused.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b52b7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \" Dall-E Mini is an open-source text-to-image AI that's available to the public but is trained on smaller datasets . It was inspired by a more powerful AI image-making tool called DALL-E,\"}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(topic5, max_length=50, min_length=15, do_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c6281f",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Pathways Autoregressive Text-to-Image model (Parti)\n",
    "Google announces new text-to-image generation model Parti. Parti follows in DALL·E's footsteps as an autoregressive model.\n",
    "Parti achieves high-fidelity photorealistic image generation and supports content-rich synthesis involving complex compositions and world knowledge.\n",
    "Parti Text-to-Image generator studies 20 billion parameters before creating an image. \n",
    "Parti uses the powerful image tokenizer, ViT-VQGAN to encode images as sequences of discrete tokens.\n",
    "Google isn't releasing Parti or Imagen to the public because AI data sets carry the risk for bias . Google says both Parti and Imagen carry bias toward Western stereotypes.\n",
    "Parti and Imagen aren't the only text-to-image models around. Dall-E, VQ-GAN+CLIP and Latent Diffusion Models are other non-Google text-to-image models that have recently made headlines. \n",
    "Dall-E Mini is an open-source text-to-image AI that's available to the public, but is trained on smaller datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7c3524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
